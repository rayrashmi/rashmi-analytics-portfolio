#  A/B Test Experiment â€” Conversion Rate Optimization

## ğŸ“Œ Project Overview
This project analyzes an A/B experiment designed to increase conversion rate on a landing page.  
Variant B introduces a simplified layout and new CTA.

## ğŸ¯ Objectives
- Measure conversion lift between Variant A and Variant B  
- Conduct statistical significance testing  
- Recommend whether to roll out the change  

## ğŸ§° Tools Used
- Python (Pandas, SciPy)
- Jupyter Notebook
- CSV dataset

## ğŸ—‚ Dataset
Columns:
- user_id  
- variant (A/B)  
- converted (0/1)  
- device  
- timestamp  

Source: Kaggle A/B Testing Dataset

## ğŸ” Statistical Tests Used
- **Chi-Square test**  
- **z-test for proportions**  
- **Effect size (Cohenâ€™s h)**  
- **Confidence interval (95%)**

## ğŸ“œ Notebook
#############################

import pandas as pd
import scipy.stats as stats

# load files
df = pd.read_csv("ab_test.csv")

# split groups
control = df[df['variant'] == 'A']
treatment = df[df['variant'] == 'B']

# conversion rates
cr_A = control['converted'].mean()
cr_B = treatment['converted'].mean()

# z-test
conv_table = pd.crosstab(df.variant, df.converted)
stat, p = stats.chi2_contingency(conv_table)[0:2]

print("CR_A:", cr_A)
print("CR_B:", cr_B)
print("Lift:", (cr_B - cr_A) / cr_A)
print("p-value:", p)

#######################
## ğŸ“ˆ Key Findings
- Variant B CR = **4.82%**  
- Variant A CR = **4.29%**  
- **Lift = +12.4%**  
- p-value < 0.05 â†’ statistically significant  

## ğŸ Recommendation
â¡ï¸ **Roll out Variant B** â€” statistically significant improvement in conversions.
